# Module 3: Optimize Producer and Consumer Performance
## Student Lab Guide

---

## üìö Module Overview

In this module, you'll learn to optimize Kafka performance through producer batching, compression, consumer fetch tuning, and broker-side configuration. You'll use performance testing tools to measure improvements and understand trade-offs between throughput and latency.

**Learning Objectives:**
- Optimize producer configurations for maximum throughput while meeting latency SLAs
- Compare compression algorithms and select the best for your use case
- Tune consumer fetch settings to prevent timeouts and rebalancing
- Understand broker-side threading and buffer configurations

**Estimated Time:** 90 minutes (including videos and hands-on practice)

---

## üîß Lab Environment Setup

### Prerequisites
- Completed Modules 1 & 2
- Kafka cluster running (`docker-compose ps` shows all containers "Up")
- Familiarity with `kafka-producer-perf-test` tool

### Verify Your Environment

```bash
cd ~/kafka-labs

# Ensure cluster is running
docker-compose up -d
sleep 15

# Test performance tool is available
docker exec broker-1 kafka-producer-perf-test --help | head -5
```

---

## üéì Lab 1: Producer Batching and Compression

### Key Concepts

**Producer Batching:**
- `batch.size`: Maximum bytes to batch before sending (default: 16KB)
- `linger.ms`: How long to wait for batch to fill (default: 0ms)
- **Trade-off:** Larger batches = higher throughput but higher latency

**Compression:**
- Reduces network bandwidth and disk usage
- Types: `none`, `gzip`, `snappy`, `lz4`, `zstd`
- **Trade-off:** Better compression = more CPU usage

**Performance Metrics:**
- **Throughput:** Records per second or MB per second
- **Latency:** Time from produce to acknowledgment
  - P50: Median latency
  - P95: 95th percentile (only 5% slower)
  - P99: 99th percentile (worst case for most requests)

**Key Insight:** Default configs prioritize latency. Production systems usually need to optimize for throughput.

---

### Exercise 1.1: Baseline Performance Test

**Task:** Measure default producer performance.

```bash
# Create test topic
kafka-topics --create \
  --topic perf-test \
  --partitions 12 \
  --replication-factor 3 \
  --config min.insync.replicas=2

# Run baseline test (defaults: 16KB batch, 0ms linger, no compression)
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=16384 \
    linger.ms=0 \
    compression.type=none
```

**Expected Output:**
```
1000000 records sent, 45123.45 records/sec (44.07 MB/sec),
12.34 ms avg latency, 28.56 ms max latency,
10 ms 50th, 25 ms 95th, 31 ms 99th, 35 ms 99.9th.
```

**Record Your Results:**
```
Baseline Performance:
Throughput: _____ records/sec
Average Latency: _____ ms
P95 Latency: _____ ms
P99 Latency: _____ ms
```

---

### Exercise 1.2: Optimize Batch Size

**Task:** Test larger batch sizes to improve throughput.

```bash
# Test 1: 32KB batches
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=32768 \
    linger.ms=0 \
    compression.type=none

# Test 2: 64KB batches
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=65536 \
    linger.ms=0 \
    compression.type=none

# Test 3: 128KB batches
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=131072 \
    linger.ms=0 \
    compression.type=none
```

**Record Your Results:**
```
Batch Size Comparison:
16KB  (baseline): _____ rec/sec, _____ ms P95
32KB: _____ rec/sec (+___%), _____ ms P95
64KB: _____ rec/sec (+___%), _____ ms P95
128KB: _____ rec/sec (+___%), _____ ms P95
```

**Questions to Answer:**
1. At what batch size did you see diminishing returns?
2. Did latency increase significantly with larger batches?
3. What batch size gives the best throughput/latency balance?

---

### Exercise 1.3: Add Linger Time

**Task:** Allow batches to fill by waiting a few milliseconds.

```bash
# Test with 128KB batch + 10ms linger
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=131072 \
    linger.ms=10 \
    compression.type=none
```

**Questions to Answer:**
1. Did throughput improve compared to 128KB batch with 0ms linger?
2. How much did P95 latency increase?
3. Is the trade-off worth it for your use case?

---

### Exercise 1.4: Test Compression Algorithms

**Task:** Compare different compression types.

```bash
# Test 1: lz4 compression (fast, good ratio)
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=131072 \
    linger.ms=10 \
    compression.type=lz4

# Test 2: snappy compression (very fast, moderate ratio)
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=131072 \
    linger.ms=10 \
    compression.type=snappy

# Test 3: zstd compression (slower, best ratio)
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=131072 \
    linger.ms=10 \
    compression.type=zstd

# Test 4: gzip compression (slowest, highest ratio)
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 1000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=131072 \
    linger.ms=10 \
    compression.type=gzip
```

**Record Your Results:**
```
Compression Comparison (128KB batch, 10ms linger):
none:   _____ rec/sec, _____ ms P95
lz4:    _____ rec/sec, _____ ms P95
snappy: _____ rec/sec, _____ ms P95
zstd:   _____ rec/sec, _____ ms P95
gzip:   _____ rec/sec, _____ ms P95
```

**Questions to Answer:**
1. Which compression gave the best throughput?
2. Which had the lowest latency?
3. When would you choose gzip despite lower throughput?

---

### Exercise 1.5: Calculate Your Improvement

**Task:** Compare your best configuration to baseline.

```
Baseline (from Exercise 1.1):     _____ rec/sec
Best Optimized (your best test):  _____ rec/sec

Improvement: _____ % increase

Configuration Used:
- batch.size: _____
- linger.ms: _____
- compression.type: _____
```

**Typical Results:**
Most students see 3-5x improvement with proper tuning!

---

### üí° Key Takeaway

**Production Recommendations:**
- **batch.size:** 128KB-256KB for high throughput
- **linger.ms:** 5-20ms (acceptable latency increase)
- **compression.type:** `lz4` for most workloads (best speed/ratio balance)
- **acks:** `all` for durability (despite performance cost)

---

## üéì Lab 2: Consumer Fetch Optimization

### Key Concepts

**Consumer Fetch Settings:**
- `fetch.min.bytes`: Minimum data to fetch (default: 1 byte)
- `fetch.max.wait.ms`: Max time to wait for `fetch.min.bytes` (default: 500ms)
- `max.poll.records`: Max records returned per poll (default: 500)

**The Rebalancing Problem:**
- Consumer must call `poll()` within `max.poll.interval.ms` (default: 5 min)
- If processing takes too long ‚Üí timeout ‚Üí rebalancing ‚Üí chaos
- **Solution:** Size `max.poll.records` based on processing time

**Fetch Strategies:**
1. **Real-time:** Small fetch, frequent polls ‚Üí low latency
2. **Batch:** Large fetch, infrequent polls ‚Üí high throughput
3. **Heavy processing:** Small batches to avoid timeout

**Key Insight:** Configure fetch based on your processing pattern, not just throughput.

---

### Exercise 2.1: Calculate Safe max.poll.records

**Scenario:** Your consumer has these characteristics:
- Processing time: 2ms per record
- `max.poll.interval.ms`: 300,000ms (5 minutes)

**Your Task:** Calculate the maximum safe `max.poll.records`.

```
Step 1: Calculate processing time per 1000 records
        = 1000 records √ó 2ms = _____ ms

Step 2: How many batches can fit in 5 minutes?
        = 300,000ms √∑ _____ ms = _____ batches

Step 3: Add safety margin (use 20% of timeout)
        = 300,000ms √ó 0.20 = _____ ms available for one batch
        
Step 4: Max records per batch
        = _____ ms √∑ 2ms = _____ records

Safe max.poll.records: _____ (round down)
```

**Rule of Thumb:** Keep processing time under 20% of timeout.

---

### Exercise 2.2: Test Real-Time Configuration

**Task:** Configure consumer for low-latency, real-time processing.

```bash
# Create test topic with data
kafka-topics --create \
  --topic realtime-events \
  --partitions 6 \
  --replication-factor 3

# Produce test data
for i in {1..10000}; do echo "event-$i"; done | \
  kafka-console-producer --topic realtime-events

# Consume with real-time settings
kafka-console-consumer \
  --topic realtime-events \
  --from-beginning \
  --group realtime-consumer \
  --max-messages 1000 \
  --consumer-property fetch.min.bytes=1 \
  --consumer-property fetch.max.wait.ms=100 \
  --consumer-property max.poll.records=100
```

**Configuration Explanation:**
- `fetch.min.bytes=1`: Don't wait for data, return immediately
- `fetch.max.wait.ms=100`: Max 100ms wait (low latency)
- `max.poll.records=100`: Small batches, frequent polling

**Use Cases:** Fraud detection, real-time alerting, live dashboards

---

### Exercise 2.3: Test High-Throughput Configuration

**Task:** Configure consumer for batch processing, high efficiency.

```bash
# Delete previous consumer group
kafka-consumer-groups --delete --group batch-consumer 2>/dev/null || true

# Consume with batch settings
kafka-console-consumer \
  --topic realtime-events \
  --from-beginning \
  --group batch-consumer \
  --max-messages 1000 \
  --consumer-property fetch.min.bytes=102400 \
  --consumer-property fetch.max.wait.ms=500 \
  --consumer-property max.poll.records=1000
```

**Configuration Explanation:**
- `fetch.min.bytes=102400` (100KB): Wait for substantial data
- `fetch.max.wait.ms=500`: Max 500ms wait
- `max.poll.records=1000`: Large batches, fewer polls

**Use Cases:** ETL pipelines, analytics, data warehouse loading

---

### Exercise 2.4: Compare Strategies

**Task:** Understand the trade-offs.

| Strategy | fetch.min.bytes | fetch.max.wait.ms | max.poll.records | Best For |
|----------|-----------------|-------------------|------------------|----------|
| Real-time | 1 | 100 | 100-500 | Low latency, instant response |
| Balanced | 10KB | 500 | 500-1000 | Most workloads |
| High-throughput | 100KB | 500 | 1000-5000 | Batch processing, ETL |
| Heavy processing | 1 | 100 | 50-200 | ML inference, complex transforms |

**Questions to Answer:**
1. Which strategy would you use for a fraud detection system?
2. Which for loading data into a data warehouse?
3. What happens if you set `max.poll.records` too high?

---

### üí° Key Takeaway

**Consumer Tuning Guidelines:**
- **Start with:** Balanced settings (middle row in table)
- **If lag builds:** Increase `max.poll.records` or scale consumers
- **If timeouts occur:** Decrease `max.poll.records`
- **If latency matters:** Decrease `fetch.max.wait.ms`
- **If throughput matters:** Increase `fetch.min.bytes`

---

## üéì Lab 3: Broker-Side Performance Tuning

### Key Concepts

**Broker Threading:**
- `num.network.threads`: Handle request parsing/response (match CPU cores)
- `num.io.threads`: Handle disk reads/writes (2√ó disk count)

**Socket Buffers:**
- `socket.send.buffer.bytes`: OS-level send buffer
- `socket.receive.buffer.bytes`: OS-level receive buffer
- Larger = fewer TCP stalls with high throughput

**Request Flow:**
```
1. Client sends request
2. Network thread picks up, parses
3. Hands to I/O thread
4. I/O thread reads/writes disk
5. Returns to network thread
6. Network thread sends response
```

**Bottleneck Detection:**
- High `RequestQueueSize` ‚Üí Need more network threads
- High disk latency ‚Üí Need more I/O threads or faster disks
- High CPU ‚Üí Scale network threads

**Key Insight:** Broker tuning gives 10-20% improvement, not as dramatic as producer optimization.

---

### Exercise 3.1: Understand Current Broker Config

**Task:** Check your broker's current settings.

```bash
# View broker configurations
docker exec broker-1 kafka-configs \
  --bootstrap-server broker-1:29092 \
  --entity-type brokers \
  --entity-name 1 \
  --describe --all | grep -E "num.network.threads|num.io.threads|socket"
```

**Default Values (typical):**
```
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400    (100KB)
socket.receive.buffer.bytes=102400 (100KB)
```

---

### Exercise 3.2: Calculate Optimal Thread Counts

**Task:** Determine ideal settings for your hardware.

**Your System:**
```bash
# Check CPU cores
docker exec broker-1 nproc
# Result: _____ cores
```

**Recommended Configuration:**
```
num.network.threads = Number of CPU cores
                    = _____ threads

num.io.threads = 2 √ó (number of disks)
               = 2 √ó 1 disk (Docker typically uses 1)
               = 2 threads (minimum)
               = 8-16 for production with multiple disks
```

**Socket Buffers:**
```
For high-throughput systems (>100 MB/sec):
socket.send.buffer.bytes = 1048576 (1MB)
socket.receive.buffer.bytes = 1048576 (1MB)

For normal systems:
socket.send.buffer.bytes = 102400 (100KB) [default]
socket.receive.buffer.bytes = 102400 (100KB) [default]
```

---

### Exercise 3.3: Test With Current Settings

**Task:** Establish baseline with current broker config.

```bash
# Run performance test
kafka-producer-perf-test \
  --topic perf-test \
  --num-records 5000000 \
  --record-size 1024 \
  --throughput -1 \
  --producer-props \
    acks=all \
    batch.size=131072 \
    linger.ms=10 \
    compression.type=lz4
```

**Record Your Results:**
```
Baseline (default broker settings): _____ records/sec
```

**Note:** Broker tuning requires restart, which we won't do in this lab. In production, you'd:
1. Apply new configs to `server.properties`
2. Rolling restart brokers
3. Re-run performance tests
4. Expect 10-20% improvement

---

### Exercise 3.4: Understand the Complete Optimization

**Task:** Calculate total improvement from all three labs.

```
Module 3 Complete Optimization:

Lab 1 - Producer Baseline:        _____ rec/sec
Lab 1 - Producer Optimized:       _____ rec/sec (+___% improvement)

Lab 2 - Consumer tuning:          Prevents timeouts, enables stable processing

Lab 3 - Broker tuning (estimated): +15% additional improvement
                                   = _____ rec/sec (estimated final)

Total Improvement: _____% (typical: 300-500%)
```

---

### üí° Key Takeaway

**Complete Optimization Strategy:**
1. **Producer tuning (Lab 1):** 3-5x improvement (biggest impact)
2. **Consumer tuning (Lab 2):** Stability, prevents rebalancing
3. **Broker tuning (Lab 3):** 10-20% additional improvement

**Combined:** 4-6x total throughput improvement with same infrastructure!

---

## üßπ Lab Cleanup

After completing all exercises:

```bash
# Stop background processes
pkill -f kafka-console-consumer
pkill -f kafka-console-producer

# Delete test consumer groups
kafka-consumer-groups --delete --group realtime-consumer 2>/dev/null || true
kafka-consumer-groups --delete --group batch-consumer 2>/dev/null || true

# Optionally delete test topics
kafka-topics --delete --topic perf-test 2>/dev/null || true
kafka-topics --delete --topic realtime-events 2>/dev/null || true

echo "‚úÖ Module 3 labs complete!"
```

---

## üìù Module 3 Quiz

Test your understanding:

1. **Which producer setting has the BIGGEST impact on throughput?**
   - A) acks=all
   - B) batch.size and linger.ms
   - C) compression.type
   - D) num.io.threads

2. **For most workloads, the recommended compression algorithm is:**
   - A) none (no compression)
   - B) gzip (highest compression)
   - C) lz4 (best speed/ratio balance)
   - D) snappy (fastest)

3. **If your consumer processes 100 records in 5 seconds and max.poll.interval.ms=300000, what's a safe max.poll.records?**
   - A) 100
   - B) 1000
   - C) 6000
   - D) 60000

4. **num.network.threads should be set to:**
   - A) 1 (single-threaded)
   - B) Number of CPU cores
   - C) 2 √ó number of disks
   - D) Number of partitions

5. **In production optimization, which gives the largest improvement?**
   - A) Broker threading (100x)
   - B) Consumer fetch settings (10x)
   - C) Producer batching (3-5x)
   - D) All equal (~20% each)

**Answers:** 1-B, 2-C, 3-B, 4-B, 5-C

---

## üîó Additional Resources

### Official Documentation
- [Producer Configurations](https://kafka.apache.org/documentation/#producerconfigs)
- [Consumer Configurations](https://kafka.apache.org/documentation/#consumerconfigs)
- [Broker Configurations](https://kafka.apache.org/documentation/#brokerconfigs)
- [Performance Tuning](https://kafka.apache.org/documentation/#hwandos)

### Real-World Optimization Stories
- [LinkedIn's Kafka at Scale](https://engineering.linkedin.com/kafka/running-kafka-scale)
- [Uber's Kafka Optimization](https://www.uber.com/blog/kafka/)
- [Confluent Performance Best Practices](https://www.confluent.io/blog/optimizing-apache-kafka-deployment/)

### Tools
- [kafka-producer-perf-test](https://kafka.apache.org/documentation/#producerperf)
- [kafka-consumer-perf-test](https://kafka.apache.org/documentation/#consumerperf)
- [JMX Monitoring](https://kafka.apache.org/documentation/#monitoring)

---

## ‚úÖ Module 3 Completion Checklist

- [ ] Completed Lab 1: Producer Batching and Compression
- [ ] Completed Lab 2: Consumer Fetch Optimization
- [ ] Completed Lab 3: Broker-Side Tuning
- [ ] Achieved 3x+ throughput improvement
- [ ] Passed Module 3 Quiz (4/5 correct minimum)
- [ ] Ready for course-end project

---

## üéì Course Project: Real-World Optimization

Now that you've completed all three modules, apply everything you've learned:

**Scenario:** You're the platform engineer at an e-commerce company. Build and optimize a Kafka cluster that:

1. **Module 1 Skills:** Configure topics for orders, inventory, and analytics with appropriate replication and partitions
2. **Module 2 Skills:** Set up monitoring, consumer groups, and alerting
3. **Module 3 Skills:** Optimize for 100,000 orders/day with <50ms P95 latency

**Deliverables:**
- Topic configurations
- Consumer group sizing calculations
- Performance test results showing improvement
- Monitoring/alerting configuration
- Documentation explaining decisions

---

**Congratulations on completing Module 3! üéâ**

You now have the skills to design, monitor, and optimize production Kafka systems. You've learned to balance throughput, latency, durability, and cost - the key trade-offs in distributed systems engineering.

**Next Steps:**
- Complete the course-end project
- Build your own Kafka application
- Earn your Kafka certification
- Join the Kafka community!
